---
title: "Capstone Project"
author: "Katie Wilson"
date: "December 4, 2017"
output: html_document
---

_Would you know how to travel around New York City as a pedestrian the first time you ever visited? Neither would I. Certain areas of the city are clearly more populous, and probably more dangerous, for someone unfamiliar with the pace and layout of the city. In this project, I will attempt to identify the areas in each of the five boroughs of New York where the majority of accidents happen and what days and times are the safest for pedestrians in those more dangerous areas._

####Section 1: Original Traffic Dataset Work
#####Using the NYCDOT open data

Load libraries used

```{r load_libraries, message=FALSE}
library(tidyr)
library(ggplot2)
library(dplyr)
library(readr)
library(rgdal)
library(maptools)
library(ggmap)
library(maps)
library(jsonlite)
library(lubridate)
library(RSocrata)
library(scales)
```

The New York City Department of Transportation website has open data available to the public with historical records of motor vehicle accidents. Two of these files have recorded all fatalities and injuries from 2011 to 2016. These files are in json format which can be directly read into R.

```{r download_data}
json_uri <- "http://www.nyc.gov/html/dot/downloads/misc/fatality_all_monthly.json"
ny_fatalities_js <- fromJSON(txt = json_uri, flatten = TRUE)
ny_fatalities_df <- ny_fatalities_js$features

json_uri2 <- "http://www.nyc.gov/html/dot/downloads/misc/injury_all_monthly.json"
ny_injuries_js <- fromJSON(txt = json_uri2, flatten = TRUE)
ny_injuries_df <- ny_injuries_js$features
```

With the format of these files, there needs to be some tidying done in order for R to read it as a dataframe and recognize the coordinates as geometric properites. They are currently being read in as a list within a column which does not convert to a dataframe. In order to correct this, each part of the list needs to be read into its own column. This saves the coordinates into a longitude and latitude column. These need to be read back into the original dataframe and the original list column can be deleted to minimize the size. I also change the properties of a few other columns in order to more easily edit the data.

```{r coordinates}
x <- rep(NA, times = length(ny_fatalities_df$geometry.coordinates))
y <- rep(NA, times = length(ny_fatalities_df$geometry.coordinates))
for(i in 1:length(ny_fatalities_df$geometry.coordinates)) {
  x[i] <- ny_fatalities_df$geometry.coordinates[[i]][1]
  y[i] <- ny_fatalities_df$geometry.coordinates[[i]][2]
}

z <- rep(NA, times = length(ny_injuries_df$geometry.coordinates))
m <- rep(NA, times = length(ny_injuries_df$geometry.coordinates))
for(i in 1:length(ny_injuries_df$geometry.coordinates)) {
  z[i] <- ny_injuries_df$geometry.coordinates[[i]][1]
  m[i] <- ny_injuries_df$geometry.coordinates[[i]][2]
}

ny_fatalities_df <- ny_fatalities_df %>% 
  mutate(latitude = x,
         longitude = y,
         geometry.coordinates = NULL,
         properties.YR = as.integer(properties.YR),
         properties.MN = as.integer(properties.MN))

ny_injuries_df <- ny_injuries_df %>% 
  mutate(latitude = z,
         longitude = m,
         geometry.coordinates = NULL,
         properties.YR = as.integer(properties.YR),
         properties.MN = as.integer(properties.MN))
```

The date in this dataframe is not in a format that will be able to be plotted. There are a few things that need to be done to get it into that state: adding in a column with the day, uniting the columns with the month, day, and year, read that column in as a date, and remove any rows that do not have a date associated with them.

```{r Date_edit}
ny_fatalities_df$properties.Day <- 1L
ny_injuries_df$properties.Day <- 1L
ny_fatalities_df <- unite(ny_fatalities_df, "FullDate",
                               c("properties.YR", "properties.MN", "properties.Day"), sep = "-")
ny_injuries_df <- unite(ny_injuries_df, "FullDate",
                             c("properties.YR", "properties.MN", "properties.Day"), sep = "-")
ny_fatalities_df$FullDate <- as.Date(ny_fatalities_df$FullDate, format = "%Y-%m-%d")
ny_injuries_df$FullDate <- as.Date(ny_injuries_df$FullDate, format = "%Y-%m-%d")
sum(is.na(ny_fatalities_df))
ny_fatalities_df <- ny_fatalities_df[complete.cases(ny_fatalities_df$FullDate), ]
sum(is.na(ny_injuries_df))
```

Since the sum of the is.na(ny_injuries_df) = 0, there are no rows to be removed from that one as there were in the fatalities dataframe. From here, we are able to do a general, basic plot of each dataframe by the date.

```{r basic_plot, fig.height=5, fig.width=7}
ggplot(ny_fatalities_df, aes(x = FullDate, y = properties.Fatalities)) +
  geom_point()
ggplot(ny_injuries_df, aes(x = FullDate, y = properties.Injuries)) +
  geom_point()
```

Although these plots are helpful and generally informative, I would like to be able to look at the injury and fatality data on the same plot. Before combining the datasets, it is necessary to determine if there are any duplicates between the two files. There are already latitude and longitude indicators on each accident along with the month in which it occurred. The problem arises if there is more than one accident at the same location within a month. First, I used paste() to combine the date, latitude, and longitude to create a unique identifier for each accident. Second, I checked the unique count of this identifier against the length of the entire dataset. If those numbers are equal, there are no duplicates between the month and the location.

```{r unique_identifier}
ny_fatalities_df$Identifier <- 
  paste(ny_fatalities_df$FullDate,
        ny_fatalities_df$latitude + ny_fatalities_df$longitude,
        sep = "")
length(unique(ny_fatalities_df$Identifier)) == nrow(ny_fatalities_df)

ny_injuries_df$Identifier <- 
  paste(ny_injuries_df$FullDate,
        ny_injuries_df$latitude + ny_injuries_df$longitude,
        sep = "")
length(unique(ny_injuries_df$Identifier)) == nrow(ny_injuries_df)
```

Because both statements for the injuries and the fatalities returned true, this identifier is in fact unique. In order to join these two datasets, full_join() is used in order to include all instances on both datasets for any of these identifiers. This new dataset is called "accident_monthly". The two totals printed from this section will show how many lines result from the combined dataset as well as how many lines between the two datasets referred to the same accident.

```{r full_join}
nrow(ny_fatalities_df) + nrow(ny_injuries_df)
accident_monthly <- full_join(ny_fatalities_df, ny_injuries_df,
                              by = c("Identifier" = "Identifier"))
(nrow(ny_fatalities_df) + nrow(ny_injuries_df)) - nrow(accident_monthly)
```

A few more summary columns are necessary now that the data has been combined. The following code creates four summaries around the number of people affected in each of the categories - pedestrians, cyclists, drivers/passengers, and people total.

```{r summary_columns}
accident_monthly$PeopleAffected <- rowSums(accident_monthly[,c("properties.Fatalities",
                                          "properties.Injuries")], na.rm = TRUE)
accident_monthly$TotalPedestrian <- rowSums(accident_monthly[,c("properties.PedFatalit",
                                          "properties.PedInjurie")], na.rm = TRUE)
accident_monthly$TotalBike <- rowSums(accident_monthly[,c("properties.BikeFatali",
                                          "properties.BikeInjuri")], na.rm = TRUE)
accident_monthly$TotalMVO <- rowSums(accident_monthly[,c("properties.MVOFatalit",
                                          "properties.MVOInjurie")], na.rm = TRUE)

```

Now that the data has been combined, we can recreate the basic plots from earlier using the full dataset. Only step that needs to still be completed is to combine all the dates from the separate datasets into one column in order to use that as the x-axis.

```{r full_basic_plot, fig.height=5, fig.width=7}
accident_monthly$FullDate.x[is.na(accident_monthly$FullDate.x)] <- (accident_monthly$FullDate.y[is.na(accident_monthly$FullDate.x)])
ggplot(accident_monthly, aes(x = FullDate.x, y = PeopleAffected)) +
  geom_point()
```



The following map gives a general outline for where the accidents take place. The acutal detailed mapping of the data will take place late on, but for now, this gives a good picture of the city with the fatality causing accidents. This would be rather overwhelming and not descriptive to use with the full dataset at this point.

```{r basic_map, fig.height=5, fig.width=7}
nyc_map <- get_map("new york", zoom = 10)
ggmap(nyc_map) +
  geom_point(data = ny_fatalities_df %>%
               filter(properties.PedFatalit > 0),
                      aes(x = latitude, y = longitude,
                          colour = properties.PedFatalit),
             alpha = 0.5, size = 0.5)
```

####Section 2: Speed Limit Data
#####Also using data from the NYCDOT

The DOT also has a great deal of information on speed limits within the city of New York. As this would help to understand whether accidents tend to happen in areas with higher or lower speed limits, I jumped at the chance to be able to input and analyze this data. It also comes in a json format which is read into R below; however, the website has one file per borough so all of the data wrangling must be done five times. In order to keep the environment clear and as much memory free as possible, all the json_uri values that were just created can be removed from the environment as they are assigned to other values. The last line of code below does just that as well as removes some of the temporary variables created earlier.


```{r speedlimit_json}
json_uri3 <- "http://www.nyc.gov/html/dot/downloads/misc/speed_limit_bronx.json"
speedlimits_Bronx_js <- fromJSON(txt = json_uri3, flatten = TRUE)
speedlimits_Bronx_df <- speedlimits_Bronx_js$features

json_uri4 <- "http://www.nyc.gov/html/dot/downloads/misc/speed_limit_brooklyn.json"
speedlimits_Brooklyn_js <- fromJSON(txt = json_uri4, flatten = TRUE)
speedlimits_Brooklyn_df <- speedlimits_Brooklyn_js$features

json_uri5 <- "http://www.nyc.gov/html/dot/downloads/misc/speed_limit_manhattan.json"
speedlimits_Manhattan_js <- fromJSON(txt = json_uri5, flatten = TRUE)
speedlimits_Manhattan_df <- speedlimits_Manhattan_js$features

json_uri6 <- "http://www.nyc.gov/html/dot/downloads/misc/speed_limit_queens.json"
speedlimits_Queens_js <- fromJSON(txt = json_uri6, flatten = TRUE)
speedlimits_Queens_df <- speedlimits_Queens_js$features

json_uri7 <- "http://www.nyc.gov/html/dot/downloads/misc/speed_limit_statenisland.json"
speedlimits_StatenIsland_js <- fromJSON(txt = json_uri7, flatten = TRUE)
speedlimits_StatenIsland_df <- speedlimits_StatenIsland_js$features

rm(json_uri, json_uri2, json_uri3, json_uri4, json_uri5, json_uri6, json_uri7, m, x, y, z)
```

In looking into the coordinate columns in this dataset, you can see that they read in as a list inside the dataframe. There isn't a lot of detail about this dataset on the website, but from a cursory look at the coordinate sections, these are most likely areas of a road that have a certain speed limit. These have been put in the dataset in list form. In order to properly view this as a dataframe, the list will need to be read into four separate columns - start latitude, start longitude, end latitude, and end longitude. The following code is an attempt to turn this list into those four separate columns using a for loop; however, as mentioned previously, there are five sets of data - one from each borough. This loop needs to be run on each of those datasets.

```{r speedlimit_column_conversion}
a <- rep(NA, times = length(speedlimits_Bronx_df$geometry.coordinates))
b <- rep(NA, times = length(speedlimits_Bronx_df$geometry.coordinates))
c <- rep(NA, times = length(speedlimits_Bronx_df$geometry.coordinates))
d <- rep(NA, times = length(speedlimits_Bronx_df$geometry.coordinates))
for(i in 1:length(speedlimits_Bronx_df$geometry.coordinates)) {
  a[i] <- speedlimits_Bronx_df$geometry.coordinates[[i]][1]
  b[i] <- speedlimits_Bronx_df$geometry.coordinates[[i]][2]
  c[i] <- speedlimits_Bronx_df$geometry.coordinates[[i]][3]
  d[i] <- speedlimits_Bronx_df$geometry.coordinates[[i]][4]
}

speedlimits_Bronx_df <- speedlimits_Bronx_df %>% 
  mutate(start_latitude = a,
         start_longitude = c,
         end_latitude = b,
         end_longitude = d,
         geometry.coordinates = NULL)

a <- rep(NA, times = length(speedlimits_Brooklyn_df$geometry.coordinates))
b <- rep(NA, times = length(speedlimits_Brooklyn_df$geometry.coordinates))
c <- rep(NA, times = length(speedlimits_Brooklyn_df$geometry.coordinates))
d <- rep(NA, times = length(speedlimits_Brooklyn_df$geometry.coordinates))
for(i in 1:length(speedlimits_Brooklyn_df$geometry.coordinates)) {
  a[i] <- speedlimits_Brooklyn_df$geometry.coordinates[[i]][1]
  b[i] <- speedlimits_Brooklyn_df$geometry.coordinates[[i]][2]
  c[i] <- speedlimits_Brooklyn_df$geometry.coordinates[[i]][3]
  d[i] <- speedlimits_Brooklyn_df$geometry.coordinates[[i]][4]
}

speedlimits_Brooklyn_df <- speedlimits_Brooklyn_df %>% 
  mutate(start_latitude = a,
         start_longitude = c,
         end_latitude = b,
         end_longitude = d,
         geometry.coordinates = NULL)

a <- rep(NA, times = length(speedlimits_Manhattan_df$geometry.coordinates))
b <- rep(NA, times = length(speedlimits_Manhattan_df$geometry.coordinates))
c <- rep(NA, times = length(speedlimits_Manhattan_df$geometry.coordinates))
d <- rep(NA, times = length(speedlimits_Manhattan_df$geometry.coordinates))
for(i in 1:length(speedlimits_Manhattan_df$geometry.coordinates)) {
  a[i] <- speedlimits_Manhattan_df$geometry.coordinates[[i]][1]
  b[i] <- speedlimits_Manhattan_df$geometry.coordinates[[i]][2]
  c[i] <- speedlimits_Manhattan_df$geometry.coordinates[[i]][3]
  d[i] <- speedlimits_Manhattan_df$geometry.coordinates[[i]][4]
}

speedlimits_Manhattan_df <- speedlimits_Manhattan_df %>% 
  mutate(start_latitude = a,
         start_longitude = c,
         end_latitude = b,
         end_longitude = d,
         geometry.coordinates = NULL)

a <- rep(NA, times = length(speedlimits_Queens_df$geometry.coordinates))
b <- rep(NA, times = length(speedlimits_Queens_df$geometry.coordinates))
c <- rep(NA, times = length(speedlimits_Queens_df$geometry.coordinates))
d <- rep(NA, times = length(speedlimits_Queens_df$geometry.coordinates))
for(i in 1:length(speedlimits_Queens_df$geometry.coordinates)) {
  a[i] <- speedlimits_Queens_df$geometry.coordinates[[i]][1]
  b[i] <- speedlimits_Queens_df$geometry.coordinates[[i]][2]
  c[i] <- speedlimits_Queens_df$geometry.coordinates[[i]][3]
  d[i] <- speedlimits_Queens_df$geometry.coordinates[[i]][4]
}

speedlimits_Queens_df <- speedlimits_Queens_df %>% 
  mutate(start_latitude = a,
         start_longitude = c,
         end_latitude = b,
         end_longitude = d,
         geometry.coordinates = NULL)

a <- rep(NA, times = length(speedlimits_StatenIsland_df$geometry.coordinates))
b <- rep(NA, times = length(speedlimits_StatenIsland_df$geometry.coordinates))
c <- rep(NA, times = length(speedlimits_StatenIsland_df$geometry.coordinates))
d <- rep(NA, times = length(speedlimits_StatenIsland_df$geometry.coordinates))
for(i in 1:length(speedlimits_StatenIsland_df$geometry.coordinates)) {
  a[i] <- speedlimits_StatenIsland_df$geometry.coordinates[[i]][1]
  b[i] <- speedlimits_StatenIsland_df$geometry.coordinates[[i]][2]
  c[i] <- speedlimits_StatenIsland_df$geometry.coordinates[[i]][3]
  d[i] <- speedlimits_StatenIsland_df$geometry.coordinates[[i]][4]
}

speedlimits_StatenIsland_df <- speedlimits_StatenIsland_df %>% 
  mutate(start_latitude = a,
         start_longitude = c,
         end_latitude = b,
         end_longitude = d,
         geometry.coordinates = NULL)

rm(a, b, c, d, i)
```

Now that all of these are converted to separate columns and the temporary variables have been removed from the environment, they can all be combined into one dataframe.

```{r speedlimit_join_datasets}
speedlimits_NY <- bind_rows(speedlimits_Bronx_df, speedlimits_Brooklyn_df,
                            speedlimits_Manhattan_df, speedlimits_Queens_df,
                            speedlimits_StatenIsland_df)
```

In reviewing this dataset, it appears some of the start combinations and end combinations of coordinates are not pairing up correctly between latitude and longitude. I went back to the original datasets pulled from the DOT website and it appears that these lists are not always of length 4. Some of them go up to 14. With a lack of explanation on the website as to what these actually refer to as well as the inconsistency in lengths of this list, I'm forced to move on without this dataset. Any attempts to clean this up and make it usable extend quite far beyond the point of this project and course. Perhaps at a later time, I'll be able to come back and look into this further.

####Section 3: 
#####NYPD Accident Data

When returning to the accident data after this, I realized that the sample set was not nearly large enough to include all the analyses I wanted to do. After quite a bit more digging, I found a dataset on the NYPD website that had over a million lines of data. This was much more suitible to the analyses and visualizations I wanted to use. In order to input this data into R, I needed to utilize an API key, save it locally as an RDS file, and then read it into R.

```{r NYPD_API_key}
ny_uri <- "https://data.cityofnewyork.us/resource/qiz3-axqb.csv"
ny_api <- validateUrl(ny_uri, "N2gcj5lI3SeIYCzuSMIGrZldx")
ny_df <- read.socrata(ny_api) %>% 
  as_data_frame()
saveRDS(object = ny_df, file = "data-raw/nypd_motor_vehicle_collisions.rds")
ny_df <- readRDS("data-raw/nypd_motor_vehicle_collisions.rds")
rm(ny_api, ny_uri)
```

For this dataset, a couple small corrections were needed for the type of data that was listed in the original file. The date field wasn't being read by R as a date so I used the lubridate package to fix that. There were also zeros listed in the latitude and longitude columns that needed to be changed to NAs. Lastly, there were blanks in the boroughs column that also needed to be change to NAs.

```{r NYPD_Data_Wrangling}
#Date
ny_df$date_time <- paste(ny_df$date, ny_df$time, sep = " ")
ny_df$date_time <- as.Date(ny_df$date_time, format = "%Y-%m-%d %H:%M")
ny_df$date <- as.Date(ny_df$date, format = "%Y-%m-%d")
#Latitude and Longitude
ny_df$latitude[ny_df$latitude == 0] <- NA
ny_df$longitude[ny_df$longitude == 0] <- NA
#Boroughs
ny_df$borough[ny_df$borough == ""] <- NA
```

After this, I wanted to see a few summaries of the file including preliminary graphs to identify any trends.

```{r NYPD_Summaries}
#Date Summary by Month
ny_df$month <- month(ny_df$date_time)
summary(month(ny_df$date_time))
#Persons Injured by Year
ggplot(data = ny_df, aes(x = date, y = number_of_persons_injured)) +
  stat_summary(fun.y = sum, 
               geom = "bar") + 
  scale_x_date(labels = date_format("%Y-%m"),
    date_breaks = "1 year")
#Persons Killed by Year
ggplot(data = ny_df, aes(x = date, y = number_of_persons_killed)) +
  stat_summary(fun.y = sum, 
               geom = "bar") + 
  scale_x_date(labels = date_format("%Y-%m"),
    date_breaks = "1 year")
```

After seeing those summary graphs, I wanted to break it down by year in order to identify any trends more specifically. The following graph shows the number of people injured each month with the different years colored.

```{r NYPD_byYear}
ny_df %>% filter(date < as.Date('2017-10-01')) %>% 
  ggplot(aes(month(date, label = TRUE, abbr = TRUE), number_of_persons_injured,
             group = factor(year(date)), colour = factor(year(date)))) +
  stat_summary(fun.y = sum, geom = "line")
```

Breaking that down further by borough, it's interesting to see the differences in each place. This next graph shows the same distribution, but filtered to only include the Bronx.

```{r NYPD_BronxByYear}
ny_df %>% filter(date < as.Date('2017-10-01'), borough == "BRONX") %>% 
  ggplot(aes(month(date, label = TRUE, abbr = TRUE), number_of_persons_injured,
               group = factor(year(date)), colour = factor(year(date)))) +
  stat_summary(fun.y = sum, geom = "line")
```

The dataset also includes the time of the day the accidents occurred. Breaking out the time and hour from the date column allows us to view the data by the time of the day. The following breakdown shows the sum of people injured by each hour of the day faceted by borough.

```{r NYPD_byHour}
ny_df$time <- hm(ny_df$time)
ny_df$hour <- hour(ny_df$time)
ny_df %>% filter(date < as.Date('2017-10-01')) %>% 
  ggplot(aes(hour, number_of_persons_injured)) +
  stat_summary(fun.y = sum, geom = "bar") +
  facet_grid(. ~ borough)
```

The sum of the number of people injured is an interesting thing, but another way to look at this data would be through averages. On average, how many people were injured each month in each borough? However, with the total data in the form it is currently in, these numbers are very hard to come by. The next step in this process is to create summary data sets that take all of this into consideration and provide a better way of analyzing the data.

There are a few other defining characteristics in this dataset including the zip code/borough, the type of vehicle, and the contributing factor. A good preliminary way to summarize this data is through tables. These three are put into tables below and ordered lowest to highest.

```{r NYPD_tables}
boroughTable <- table(ny_df$borough)
boroughTable[order(boroughTable)]
vehicleTable <- table(ny_df$vehicle_type_code1)
vehicleTable[order(vehicleTable)]
factorTable <- table(ny_df$contributing_factor_vehicle_1)
factorTable[order(factorTable)]
```

Usually, the most important contributors will be the top 5-10 categories depending on the distribution. There is an Unspecified category for the contributing factor and an Unknown in the vehicle table. As these do not give us any helpful trending information, they will be filtered out when we summarize the data.

The first summary I would like to see is over the boroughs. There are two different null values I want to account for, the NA in the borough and the zeros in the number of persons injured/killed. To summarize correctly, I would need to apply the filters first to each individual dataset, run the summarise function, and then do a full join afterwards.

```{r Summary_byBorough}
NPI_summary <- ny_df %>% 
  filter(borough != "", number_of_persons_injured > 0) %>% 
  group_by(borough) %>% 
  summarise(avgInjury = mean(number_of_persons_injured, is.na = TRUE))

NPK_summary <- ny_df %>% 
  filter(borough != "", number_of_persons_killed > 0) %>% 
  group_by(borough) %>% 
  summarise(avgFatality = mean(number_of_persons_killed, is.na = TRUE))

Borough_summary <- full_join(NPI_summary, NPK_summary, by = "borough")
rm(NPK_summary, NPI_summary)
Borough_summary
```

Next, I would like to be able to see a general summary by month and year of the incident. I will have to do the same thing as above with doing a full join afterwards. This, however, will need to include unique identifiers for each month in order to make sure all the data is included from each of the tables.

```{r Summary_byMonth}
NPI_bydate <- ny_df %>% 
  filter(borough != "", number_of_persons_injured > 0) %>% 
  mutate(year = year(date_time)) %>% 
  group_by(year, month, borough) %>% 
  summarise(avgTotalInjury = mean(number_of_persons_injured, is.na = TRUE))

NPK_bydate <- ny_df %>% 
  filter(borough != "", number_of_persons_killed > 0) %>% 
  mutate(year = year(date_time)) %>% 
  group_by(year, month, borough) %>% 
  summarise(avgTotalKilled = mean(number_of_persons_killed, is.na = TRUE))

# Create Unique Identifiers for each summary table
NPI_bydate$Unique <- paste(NPI_bydate$year, NPI_bydate$month,
                           NPI_bydate$borough, sep = "")
NPK_bydate$Unique <- paste(NPK_bydate$year, NPK_bydate$month,
                           NPK_bydate$borough, sep = "")

# Join them into a total month summary table
mmyyyy_summary <- full_join(NPI_bydate, NPK_bydate, by = "Unique")

rm(NPI_bydate, NPK_bydate)
mmyyyy_summary
```

